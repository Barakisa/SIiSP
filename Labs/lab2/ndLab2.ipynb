{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Neuron:\n",
    "    weights = []\n",
    "\n",
    "    # weightcount is the number of inputs\n",
    "    def __init__(self, weightcount):\n",
    "        self.weights = [random.random() for _ in range(weightcount)]\n",
    "\n",
    "    # w[0] is the bias, x[0] = 1\n",
    "    def param_sum(self, x):\n",
    "        w = self.weights\n",
    "        return sum(w[i]*x[i] for i in range(len(x)))\n",
    "    \n",
    "    def threshold(self, x):\n",
    "        if self.param_sum(x) > THRESHOLD:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuplift target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuplify(dataLine):\n",
    "    target = dataLine.pop()\n",
    "    return (dataLine, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because in my dataset, I have changed the target values to 0 and 1\n",
    "nameIdMap = {0: \"Iris-versicolor\", 1: \"Iris-virginica\"}\n",
    "\n",
    "with open(\".\\iris\\iris.testingdata\", \"r\") as file:\n",
    "    irisTestingDataTemp = file.read().split(\"\\n\")\n",
    "\n",
    "with open(\".\\iris\\iris.trainingdata\", \"r\") as file:\n",
    "    irisTrainingDataTemp = file.read().split(\"\\n\")\n",
    "\n",
    "irisTrainingData = [tuplify(list(map(float, line.split(\",\")))) for line in irisTrainingDataTemp]\n",
    "irisTestingData = [tuplify(list(map(float, line.split(\",\")))) for line in irisTestingDataTemp]\n",
    "\n",
    "\n",
    "print(\"Data from file:\\n\", irisTestingData, \"\\n\", irisTrainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer Wisconsin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Open the file in read mode ('r')\n",
    "with open('./breast+cancer+wisconsin+original/breast-cancer-wisconsin.data', 'r') as file:\n",
    "    # Read the entire file content\n",
    "    data = file.read()\n",
    "\n",
    "# get each line of data\n",
    "lines = data.split('\\n')\n",
    "#shuffle the data\n",
    "random.shuffle(lines)\n",
    "bcData = []\n",
    "\n",
    "for line in lines:\n",
    "    # turn csv to list\n",
    "    tempSet = line.split(',')\n",
    "    if '?' not in tempSet:\n",
    "        #remove id column\n",
    "        tempSet.pop(0)\n",
    "        # turn in to a list of floats\n",
    "        tempSet = list(map(float, tempSet))\n",
    "        #change target to 0 or 1\n",
    "        if tempSet[-1] == 2:\n",
    "            tempSet[-1] = 0\n",
    "        else:\n",
    "            tempSet[-1] = 1\n",
    "        # turn in to tuple\n",
    "        tempSetTuple = tuplify(tempSet)\n",
    "        # add to data\n",
    "        bcData.append(tempSetTuple)\n",
    "\n",
    "bcTrainingData = bcData[:math.floor(len(bcData)*0.8)]\n",
    "bcTestingData = bcData[math.floor(len(bcData)*0.8):]\n",
    "\n",
    "print(len(bcTestingData), len(bcTrainingData))\n",
    "\n",
    "print(\"Data from file:\\n\", bcTestingData, \"\\n\", bcTrainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "### Neurono mokymui naudoti stochastinį gradientinį nusileidimą ir ADALINE mokymo taisyklę\n",
    "\n",
    "Stochastic gradient descent - take training data one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(neuron, data):\n",
    "\n",
    "    loss = 0.5 * sum((target - neuron.threshold([1]+features))**2 for features, target in data)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADALINE training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features - inputs ($X$)\n",
    "\n",
    "target - the expected result ($t_i$)\n",
    "\n",
    "error - difference between what the neuron outputs (paramSum) and the target\n",
    "\n",
    "then each neuron weight gets trained based on LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "LEARNING_RATE = 0.0003\n",
    "EPOCHS_IRIS = 5000\n",
    "EPOCHS_CANCER = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainADALINE(trainingData, neuron):\n",
    "    # print(trainingData)\n",
    "    for line in trainingData:\n",
    "        features, target = line\n",
    "        #add bias\n",
    "        features = [1]+features\n",
    "        error = target - neuron.threshold(features)\n",
    "        for i in range(len(neuron.weights)):\n",
    "            neuron.weights[i] += LEARNING_RATE * error * features[i]\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetrics(neuron, trainingData, testingData):\n",
    "    allMetrics = {'trainingData':{'loss':0, 'tp': 0, 'tn': 0, 'fp':0, 'fn': 0}, \n",
    "                  'testingData' :{'loss':0, 'tp': 0, 'tn': 0, 'fp':0, 'fn': 0}}\n",
    "    \n",
    "    for metricSet, data in zip(allMetrics.keys(), [trainingData, testingData]):\n",
    "    # for metricSet, data in zip(['trainingData'], [trainingData]):\n",
    "        allMetrics[metricSet]['loss'] = loss(neuron, data)\n",
    "        for features, target in data:\n",
    "            # calculate confusion matrix\n",
    "            pred = neuron.threshold([1]+features)\n",
    "            if pred == 1:\n",
    "                if target == 1:\n",
    "                    allMetrics[metricSet]['tp'] += 1\n",
    "                else:\n",
    "                    allMetrics[metricSet]['fp'] += 1\n",
    "            else:\n",
    "                if target == 1:\n",
    "                    allMetrics[metricSet]['fn'] += 1\n",
    "                else:\n",
    "                    allMetrics[metricSet]['tn'] += 1\n",
    "        #calculate precision, recall, accuracy\n",
    "        allMetrics[metricSet]['precision'] = allMetrics[metricSet]['tp']/(allMetrics[metricSet]['tp']+allMetrics[metricSet]['fp'])\n",
    "        allMetrics[metricSet]['recall'] = allMetrics[metricSet]['tp']/(allMetrics[metricSet]['tp']+allMetrics[metricSet]['fn'])\n",
    "        allMetrics[metricSet]['accuracy'] = (allMetrics[metricSet]['tp']+allMetrics[metricSet]['tn'])/(allMetrics[metricSet]['tp']+allMetrics[metricSet]['tn']+allMetrics[metricSet]['fp']+allMetrics[metricSet]['fn'])\n",
    "        allMetrics[metricSet]['f1'] = 2*(allMetrics[metricSet]['precision']*allMetrics[metricSet]['recall'])/(allMetrics[metricSet]['precision']+allMetrics[metricSet]['recall'])\n",
    "        pass\n",
    "    return allMetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotLossAndAccuracy(allMetrics, threshold, step, mainPlot, compare = False):\n",
    "    if mainPlot == 'training':\n",
    "        losses= [metrics['trainingData']['loss'] for metrics in allMetrics]\n",
    "        accuracies = [metrics['trainingData']['accuracy'] for metrics in allMetrics]\n",
    "        precisions = [metrics['trainingData']['precision'] for metrics in allMetrics]\n",
    "        recalls = [metrics['trainingData']['recall'] for metrics in allMetrics]\n",
    "        if compare:\n",
    "            lossesComp = [metrics['testingData']['loss'] for metrics in allMetrics]\n",
    "            accuraciesComp = [metrics['testingData']['accuracy'] for metrics in allMetrics]\n",
    "            precisionsComp = [metrics['testingData']['precision'] for metrics in allMetrics]\n",
    "            recallsComp = [metrics['testingData']['recall'] for metrics in allMetrics]\n",
    "\n",
    "    elif mainPlot == 'testing' or compare:\n",
    "        losses = [metrics['testingData']['loss'] for metrics in allMetrics]\n",
    "        accuracies = [metrics['testingData']['accuracy'] for metrics in allMetrics]\n",
    "        precisions = [metrics['testingData']['precision'] for metrics in allMetrics]\n",
    "        recalls = [metrics['testingData']['recall'] for metrics in allMetrics]\n",
    "        if compare:\n",
    "            lossesComp = [metrics['trainingData']['loss'] for metrics in allMetrics]\n",
    "            accuraciesComp = [metrics['trainingData']['accuracy'] for metrics in allMetrics]\n",
    "            precisionsComp = [metrics['trainingData']['precision'] for metrics in allMetrics]\n",
    "            recallsComp = [metrics['trainingData']['recall'] for metrics in allMetrics]\n",
    "            \n",
    "\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color=color)\n",
    "    line1, = ax1.plot(losses, color=color, label='Loss - ' + mainPlot)\n",
    "    if compare:\n",
    "        line3, = ax1.plot(lossesComp, color='tab:orange', label='Loss - ' + ('training' if mainPlot == 'testing' else 'testing'))\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.set_ylim([0, max([max(losses), max(lossesComp if compare else losses)]) + 1])  # Set limits for y-axis on the left\n",
    "\n",
    "    ax2 = ax1.twinx() \n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Accuracy', color=color) \n",
    "    line2, = ax2.plot(accuracies, color=color, label='Accuracy - ' + mainPlot)\n",
    "    if compare:\n",
    "        line4, = ax2.plot(accuraciesComp, color='tab:cyan', label='Accuracy - ' + ('training' if mainPlot == 'testing' else 'testing'))\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.set_ylim([0, 1.1])  # Set limits for y-axis on the right\n",
    "\n",
    "    lines = [line1, line2]\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    if compare:\n",
    "        lines += [line3, line4]\n",
    "        labels += [l.get_label() for l in [line3, line4]]\n",
    "\n",
    "    fig.legend(lines, labels, loc='center')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title('Model Loss and Accuracy over Epochs\\nThreshold: ' + str(threshold) + '; Step: ' + str(step))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "# Create a dictionary that maps neurons and their respective data to a tuple\n",
    "# which will then be used in a generic training and testing function\n",
    "# iris has 4 inputs, cancer has 9, because the last of 5 and 10 is the target\n",
    "\n",
    "\n",
    "neurons = { \"Cancer\": (Neuron(10), bcTrainingData, bcTestingData, EPOCHS_CANCER), \"Iris\": (Neuron(5), irisTrainingData, irisTestingData, EPOCHS_IRIS)}\n",
    "\n",
    "\n",
    "# Create a ToggleButtons widget\n",
    "toggle = widgets.ToggleButtons(\n",
    "    # Use function names as options\n",
    "    options=neurons.keys(),  \n",
    "    description=f'Lern rate = {LEARNING_RATE}, \\nEpoch count: Cancer = {EPOCHS_CANCER}, Iris: {EPOCHS_IRIS}\\n Choose activation function:',\n",
    ")\n",
    "# Display the widget\n",
    "display(toggle)\n",
    "\n",
    "# Create a button that will run the selected function when clicked\n",
    "button = widgets.Button(description=\"Run\")\n",
    "\n",
    "def onRunClicked(b):\n",
    "    neuron, trainingData, testingData, epochs = neurons[toggle.value]\n",
    "    allMetrics = []\n",
    "    for i in range(epochs):\n",
    "        neuron = trainADALINE(trainingData, neuron)\n",
    "        metrics = calculateMetrics(neuron, trainingData, testingData)\n",
    "        allMetrics.append(metrics)\n",
    "\n",
    "    def niceDataPrint(dataSetToPrint):\n",
    "        allDataSets = {'Training': 'trainingData', 'Testing': 'testingData'}\n",
    "        dataSet = allDataSets[dataSetToPrint]\n",
    "        print(f\"\\n{dataSetToPrint} data:\")\n",
    "        for key, value in allMetrics[-1][dataSet].items():\n",
    "            print(f\"{key}: {value:.3f}\")\n",
    "    \n",
    "    def saveTestingDataPredictions(neuron, testingData):\n",
    "        with open('testingDataPredictions.txt', 'w') as file:\n",
    "            file.write(f\"Target / prediction | verdict: \\n\")\n",
    "            for features, target in testingData:\n",
    "                t = target\n",
    "                p = neuron.threshold([1]+features)\n",
    "                v = 'Ok' if t == p else 'Wrong'\n",
    "                file.write(f\"{t} / {p} | {v}\\n\")\n",
    "\n",
    "    # plot_loss_and_accuracy(losses_testing, accuracies_testing)\n",
    "    plotLossAndAccuracy(allMetrics, THRESHOLD, LEARNING_RATE, 'training', compare = True)\n",
    "    saveTestingDataPredictions(neuron, testingData)\n",
    "    print(f\"Metrics for the last epoch :\")\n",
    "    niceDataPrint('Training')\n",
    "    niceDataPrint('Testing')\n",
    "\n",
    "    \n",
    "    # plotLossAndAccuracy(allMetrics, THRESHOLD, LEARNING_RATE, 'testing', compare = True)\n",
    "    # niceDataPrint('Testing')\n",
    "\n",
    "\n",
    "\n",
    "# Register the callback function with the button\n",
    "button.on_click(onRunClicked)\n",
    "# Run the function to display the output\n",
    "display(button)\n",
    "# debugging only\n",
    "button.click()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
